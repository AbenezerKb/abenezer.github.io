<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects on Abenezer</title><link>https://abenezerkb.github.io/projects/</link><description>Recent content in Projects on Abenezer</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 01 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://abenezerkb.github.io/projects/index.xml" rel="self" type="application/rss+xml"/><item><title>LoRA Implementation</title><link>https://abenezerkb.github.io/projects/lora/lora-implementation/</link><pubDate>Sun, 17 Dec 2023 23:15:00 +0700</pubDate><guid>https://abenezerkb.github.io/projects/lora/lora-implementation/</guid><description>&lt;p>LoRA: Low-Rank Adaptation of Large Language Models PyTorch Implementation.&lt;/p>
&lt;p>Link for the Paper &lt;a href="https://arxiv.org/abs/2106.09685">here&lt;/a>&lt;/p>
&lt;p>Link for PyTorch Implementation &lt;a href="https://github.com/AbenezerKb/LoRA-implementation">here&lt;/a>&lt;/p></description></item><item><title>Vision Transformer Implementation</title><link>https://abenezerkb.github.io/projects/vit/vision-transformer/</link><pubDate>Tue, 11 Jul 2023 23:15:00 +0700</pubDate><guid>https://abenezerkb.github.io/projects/vit/vision-transformer/</guid><description>&lt;p>Transformer are usually used in NLP. In computer vision, attention is used with CNN as a part of it. But the paper &lt;strong>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/strong> shows that pure transformer can perform well in image classification. This is a PyTorch implementation of the project.&lt;/p>
&lt;p>&lt;a href="https://arxiv.org/abs/2010.11929">Link for the Paper&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://github.com/AbenezerKb/vision-transformer-implementation">Link for PyTorch Implementation&lt;/a>&lt;/p></description></item><item><title>Transformers Model Architecture Implementation</title><link>https://abenezerkb.github.io/projects/transformer/transformers/</link><pubDate>Sat, 11 Feb 2023 23:15:00 +0700</pubDate><guid>https://abenezerkb.github.io/projects/transformer/transformers/</guid><description>&lt;p>This is an implementation for the transformer model architecture based on the paper: Attention is all you need.&lt;/p>
&lt;p>Link for the Paper &lt;a href="https://arxiv.org/abs/1706.03762">here&lt;/a>&lt;/p>
&lt;p>Link for PyTorch Implementation &lt;a href="https://github.com/AbenezerKb/transformer-implementation">here&lt;/a>&lt;/p></description></item><item><title>Recommendation System</title><link>https://abenezerkb.github.io/projects/recommendation-system/recommendation-system/</link><pubDate>Mon, 20 Apr 2020 23:15:00 +0700</pubDate><guid>https://abenezerkb.github.io/projects/recommendation-system/recommendation-system/</guid><description>&lt;h2 id="recommendation-system">Recommendation System.&lt;/h2>
&lt;p>This is a movie recommendation system. It works based on users&amp;rsquo; ratings for collaborative filtering and it also works based on content filtering to handle cold-start problem&lt;/p>
&lt;p>The data used in this project is from &lt;a href="https://grouplens.org/datasets/movielens">this website&lt;/a>&lt;/p>
&lt;p>Link for the Project &lt;a href="https://github.com/AbenezerKb/recommender-system">here&lt;/a>&lt;/p></description></item></channel></rss>